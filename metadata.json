{
  "name": "InfinityMix",
  "description": "3.1. Idea Header\n\nWorking Title: InfinityMix\nType: Web app (AI-powered mashup generator)\nStatus: Fleshing out\n\n3.2. One-Liner\n\nUpload songs and stems, choose a duration, hit Generate, and an AI “super-mashup DJ” creates a polished mashup you can play in the browser and download.\n\n3.3. Problem & Audience\n\nTarget users: bedroom producers and DJs, online creators (YouTube / TikTok / Twitch), and music fans who want “What if this song was over that beat?” without DAWs or music theory.\n\nCore problem: good mashups are slow and technical—finding compatible songs, lining up grids, warping, pitching, arranging, mixing. Existing tools are either live DJ software (manual) or DAWs (complex). There’s no simple “upload → generate → listen & download” tool that behaves like a world-class mashup DJ.\n\nWhy now: stem separation, beat tracking and key detection are mature; AI music tools are rising; demand for fast, unique audio for social content and DJ culture is huge.\n\n3.4. Vision & Value\n\nPrimary outcome: user uploads a pool of songs/stems, sets a target length, clicks Generate, and gets mashups that are on-beat, in-key, structured, energetic, and instantly playable + downloadable.\n\nKey value promise:\n“No DAW, no music theory, no engineering. Just pick songs, choose duration, and get a DJ-level mashup you can play and download.”\n\nVibe: magical, playful, empowering. Simple UI, deep “DJ brain” underneath.\n\n3.5. Core Features (V1 Must-Haves)\n\n1) Smart Audio Analysis (“Ears”)\nPer track the system detects BPM + beat grid, key + rough harmony, song sections (intro/verse/chorus/drop/outro), does stem separation (at least vocals vs instrumental) and computes an energy curve. This is the musical context for DJ-style decisions.\n\n2) Duration-Aware Generation\nUser enters a target duration (e.g., 0:45–5:00+). The system turns time into bars/phrases at a master BPM and picks a structure:\n\nShort: quick intro → hook → outro.\n\nMedium: intro → verse → chorus → switch → outro.\n\nLong: mini DJ-set arc with multiple songs.\n\nIt rounds to full phrases instead of chopping mid-bar.\n\n3) Multi-Track Pool\nUser can upload many tracks (songs, acapellas, instrumentals, loops). Backend treats them as ingredients: chooses backbone instrumentals, vocal moments, and rotates songs in and out over time. Internally you can cap for performance, but UX says “add as many records as you want.”\n\n4) Mashup Planner (“Brain”)\nGiven analysis + duration + compatibility (key/BPM/structure) + optional vibe (safe vs experimental, chill vs hype), the planner chooses master BPM/key, 1–2 backbone instrumentals and which vocal sections go where. It builds a timeline (intro, vocal sections from different tracks, big chorus/drop moments, outro): a structured arrangement, not random overlaps.\n\n5) Rendering & Mixing\nEngine time-stretches stems to master BPM, pitch-shifts to the chosen key, places clips per the plan, adds crossfades, then does basic mixing (vocal/instrument balance, simple EQ, light compression/limiting). Output: a rendered mashup audio file (WAV or high-bitrate MP3).\n\n6) In-Browser Playback + Download\nAfter Generate, the app shows an audio player (play/pause, seek, optional waveform) and a clear “Download Mashup” button so users can immediately listen, then save the file for DJ sets, videos, etc.\n\n7) Simple Guided Flow\n\nUpload: drag-and-drop multiple audio files; optionally show detected BPM/key.\n\nSettings: set duration; optionally energy (Chill → Hype) and style (Safe → Experimental).\n\nGenerate: backend analyzes, plans, renders.\n\nPlayback & download: built-in player plus download; optionally 2–3 variants.\n\n3.6. Nice-to-Haves (Later)\n\nSong suggestions based on the user’s pool; prompt-based modes (“festival banger,” “chill flip,” “nostalgia blend”); style sliders (vocal density, weirdness, amount of switch-ups); live-performance exports (stems, cue points, loops); AI FX for transitions; a visual timeline editor where users tweak the AI’s arrangement.\n\n3.7. Constraints, Risks & MVP\n\nPlatform: Web app; heavy DSP/AI on the backend.\nTech: React/Next.js frontend; Python (FastAPI) backend; Python audio/ML stack (e.g., Spleeter/Demucs for stems, Essentia-style tools for BPM/key/structure/energy); S3-style storage; PostgreSQL; Redis + workers; GPU for stems/ML.\n\nRisks: compute cost (stems + analysis), audio quality, subjective “perfection,” copyright/legal for uploaded music, bold expectations vs early reality.\n\nTiny MVP: internally use 2–3 tracks, 1 backbone instrumental + 1 vocal track, and a couple of fixed duration templates (e.g., 1:00, 2:00). It still must generate a structured mash and provide in-browser playback + download. First steps: script the core pipeline (analyze two songs, stretch/pitch, align a chorus, export); add simple duration templates; then wrap a minimal UI (upload, choose duration preset, Generate, play/download).",
  "slug": "infinitymix-910c0b47",
  "created_at": "2025-11-28T04:16:58.532Z",
  "completed_at": "2025-11-28T04:29:11.052Z",
  "stack_choice": "custom",
  "phases_completed": [
    "ANALYSIS",
    "STACK_SELECTION",
    "SPEC",
    "DEPENDENCIES",
    "SOLUTIONING"
  ]
}